# 비지도학습 (unsupervised learning)
***
## 비지도학습이란?
- X1, X2, ... , Xp 측정에 대해 흥미로운 것들을 발견하고자 하는 것이 목적
- 반응변수 Y가 없기 때문에 예측에는 관심이 없다
- 주성분분석 : 지도기법이 적용되기 전에 데이터를 시각화 하거나 전처리 하는 데 사용되는 도구
- 클러스터링 : 데이터의 알려지지 않은 서브그룹을 발견하는 도구
- 주관적인 경향이 있고 보통 탐색적 자료분석(EDA)의 일부로서 수행된다
- 문제가 비지도적(자율적)이며, 실제로 답을 모르기 때문에, 결과를 점검할 방법이 없다
- 그러나 많은 분야에서 중요도가 증가하고 있다 (질병의 서브그룹, 검색패턴 발견 등)
***
## 주성분분석 (principal components analysis)
- 큰 데이터의 경우 쉽게 이해하기 어려움 -> 데이터를 가장 잘 설명하는 요약치가 필요
- 주성분 -> 원 데이터의 변동성을 총체적으로 설명하는 적은 수의 대표적인 변수들을 가지고 집합을 요약
- PCA란 다차원 데이터를 가능한 한 많은 변동성을 포함하는 자료로 가공해 저차원 표현을 찾는 것
- PCA는 지도학습 문제에 사용하기 위한 파생 변수들을 생성하거나 데이터 시각화를 위한 도구로 사용
- 첫 번째 주성분은 가장 큰 분산(원 데이터의 분산을 가장 잘 설명하는)을 갖게 되는 정규화된 선형결합
- 두 번째 주성분은 첫 번째 주성분과 상관되지 않고(직교/수직하는) 분산을 최대로 하는 선형결합
- 변수 스케일링이 결과에 상당한 영향을 주므로, 보통은 PCA 수행 전 표준편차가 1이 되도록 스케일링 한다
- 각 주성분에 의해 설명되는 분산의 비율(PVE) -> 스크리 그래프(scree plot)에서 확인
### 주성분분석의 과정
- "정규화"된 선형결합 -> 로딩의 제곱합이 1이 되게 제한
- 주성분분석 최적화 문제 -> 로딩, 스코어, 고유값 분해
***
## K-평균 클러스터링 (K-means clustering)
- 자료를 K개의 서로 다른 겹치지 않는 클러스터로 분할하는 기법
- 클러스터 내 변동이 가능한 한 작은 것이 좋은 클러스터링
- 클러스터 내 변동은 보통 유클리드 거리 제곱(squared Euclidean distance)으로 정의
- (1) 각 관측치에 1에서 K까지의 숫자를 랜덤하게 할당한다 
- (2) K개 클러스터 각각에 대해 무게중심을 계산한다 -> 무게중심은 관측치들의 평균
- (3) 각 관측치를 그 무게중심이 가장 가까운 클러스터에 할당한다
- 초기 클러스터 할당에 따라 결과가 달라지므로, 초기 랜덤 할당을 다르게 하여 최고 솔루션 선택
## 계층적 클러스터링 (hierarchical clustering)
- K 값의 지정이 필요하지 않은 기법, 덴드로그램으로 표현
- 트리 아래에서 융합되는 관측치들은 서로 유사, 꼭대기에서 융합되는 것은 서로 다른 경향
- 덴드로그램 절단 높이는 K-평균에서 얻어지는 클러스터 수를 제어하는 k와 같은 역할
- 각 관측치 쌍 사이의 일종의 비유사성 측도로 유클리드 거리를 정의
- 두 클러스터 사이 비유사성을 어떻게 정의? 연결(linkage)의 개념
- complete linkage : 최대 클러스터 간 비유사성, 비유사성이 가장 큰 것을 기록
- single linkage : 최소 클러스터 간 비유사성, 비유사성이 가장 작은 것을 기록
- average linkage : 평균 클러스터 간 비유사성, 비유사성이 평균을 기록
- 변수 스케일링, 유클리드 대신 상관 기반의 거리로 비유사성을 측정할 것인지 등의 고려가 필요
***
